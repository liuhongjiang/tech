<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[分类: 3rd&nbsp;tools | 刘洪江的流水帐]]></title>
  <link href="http://liuhongjiang.github.com/tech/blog/categories/3rd-nbsp-tools/atom.xml" rel="self"/>
  <link href="http://liuhongjiang.github.com/tech/"/>
  <updated>2015-07-01T14:25:44+08:00</updated>
  <id>http://liuhongjiang.github.com/tech/</id>
  <author>
    <name><![CDATA[刘洪江]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[ZooKeeper Overview]]></title>
    <link href="http://liuhongjiang.github.com/tech/blog/2013/01/23/zk-overview/"/>
    <updated>2013-01-23T17:05:00+08:00</updated>
    <id>http://liuhongjiang.github.com/tech/blog/2013/01/23/zk-overview</id>
    <content type="html"><![CDATA[<h2 id="zookeeper-">ZooKeeper 简介</h2>

<p>ZooKeeper是Hadoop的正式子项目，它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、名字服务、分布式同步、组服务等。ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup></p>

<p>Zookeeper是Google的Chubby一个开源的实现，关于Chubby，可以google一下，有论文介绍的。zookeeper是高有效和可靠的协同工作系统。Zookeeper能够用来leader选举，配置信息维护等。在一个分布式的环境中，我们需要一个Master实例或存储一些配置信息，确保文件写入的一致性等。</p>

<p>ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，包含一个简单的原语集，是Hadoop和Hbase的重要组件。目前提供Java和C的接口。</p>

<p>在Zookeeper中，znode是一个跟Unix文件系统路径相似的节点,可以往这个节点存储或获取数据.如果在创建znode时Flag设置为EPHEMERAL,那么当这个创建这个znode的节点和Zookeeper失去连接后,这个znode将不再存在在Zookeeper 里.Zookeeper使用Watcher察觉事件信息,当客户端接收到事件信息,比如连接超时,节点数据改变,子节点改变,可以调用相应的行为来处理数 据.Zookeeper的Wiki页面展示了如何使用Zookeeper来处理事件通知,队列,优先队列,锁,共享锁,可撤销的共享锁,两阶段提交.</p>

<p>znodes与Unix文件系统路径相似相似，但是还是不同的，znode的中间节点是可以保存数据的，对应于文件系统，就即是文件又是目录。为了达到高吞吐的能力，znode在zookeeper中是放在内存中的。</p>

<p>ZooKeeper是以Fast Paxos算法为基础的，paxos算法存在活锁的问题，即当有多个proposer交错提交时，有可能互相排斥导致没有一个proposer能提交成功，而Fast Paxos作了一些优化，通过选举产生一个leader，只有leader才能提交propose，具体算法可见Fast Paxos。因此，要想弄懂ZooKeeper首先得对Fast Paxos有所了解。</p>

<p>ZooKeeper的基本运转流程：</p>

<pre><code>1、选举Leader。
2、同步数据。
3、选举Leader过程中算法有很多，但要达到的选举标准是一致的。
4、Leader要具有最高的zxid。
5、集群中大多数的机器得到响应并follow选出的Leader。
</code></pre>

<!-- more -->

<h2 id="zookeeper-overview">ZooKeeper Overview</h2>

<h3 id="section">结构</h3>

<p>zookeeper service本身就是一个分布式集群，这一点和chubby是一样的。一个典型的集群由5个节点组成，他们之间选举出一个leader。构成zookeeper service的server有个前提条件，就是这些server是相互能够感知的。所有的server都保存了一个zookeeper的数据和状态的一个镜像，而且为了获得高吞吐能力，这个镜像是存放在内存中的。这个镜像是通过事务日志和某一时刻全部数据的快照生成的。</p>

<p>Zookeeper的客户端连接到zookeeper的server上，客户端保持一个与server之间的TCP连接，并通过这个TCP链接发送请求，获取响应，获取watch事件，和发送心跳。如果连接断掉了，那么客户端将会自动连接到另外一个server。</p>

<p><img class="center" src="/images/blogimages/2013/zk-overview/zkservice.jpg"> </p>

<p>zookeeper的操作是有顺序的，zookeeper为每一个操作添加一个数字，通过这个数字可以体现出所有ZooKeeper transactions的顺序。后续的操作，可以通过这个种顺序去实现更上层的应用，例如同步操作。</p>

<p>zookeeper的数据模型，类似文件系统，通过定一个了Hierarchical Namespace的概念，一个name就是路径，每一个节点znode都是通过一个路径来定义的。ZooKeeper's Hierarchical Namespace的一个示例：</p>

<p><img class="center" src="/images/blogimages/2013/zk-overview/zknamespace.jpg"> </p>

<h3 id="section-1">节点和临时节点</h3>

<p>在zookeeper中，每个节点(znode)可以包含数据信息。就像传统的文件系统中，允许既可以是文件，又可以是目录。
zookeeper的设计目的就是存放同步信息：状态信息，配置，位置信息等等。所以每个节点存放的数据都是非常小的。具体实现是，可能是一个路径对应DB中的一项数据，例如chubby就是使用Berkeley DB来保存Node的信息。</p>

<p>znode实际上包含的是一个有状态的数据，它包含了数据变更的版本号，ACL(Access Control List)变更的版本号，时间戳。每次数据变更时，version就是增加。例如，每次客户端查找收到一个node的数据，同时还会收到这个数据的版本号。</p>

<p>znode的数据操作是原子性的，读操作将会获取znode的所有数据，写操作操作将会覆盖所有的数据。而且没有节点的都通过ACL来限制谁可以操作。</p>

<p>zookeeper还支持临时节点，当创建临时节点的session结束时，临时节点也会被zookeeper删除。例如，可以利用这种机制监控系统中有哪些client不存在了。</p>

<h3 id="conditional-updates-and-watches">Conditional updates and watches</h3>

<p>zookeeper支持watch事件，客户端可以向一个znode注册一个watch事件。当这个节点发生改变时，这个watch事件将被激活，同时被注销。当一个watch事件触发是，zookeeper将会给客户端发送一个通知消息。如果客户端和zookeeper servers直接的连接断掉了，那么客户端会收到本地的一条连接断掉的消息。</p>

<h3 id="guarantees">保证(Guarantees)</h3>

<p>zookeeper非常简单快速，它的设计目的，是在它之上可以构造复杂的服务，例如同步。那么zookeeper就应该向上提供一些保证：</p>

<ul>
  <li>序列一致性：从一个客户端发送的一系列更新操作，讲会按照发送顺序执行。</li>
  <li>原子性：更新要么成功，要么失败，没有中间状态，不会一部分成功，一部分失败。</li>
  <li>数据一致性：在客户端看来，所有的服务和数据都是一样的，无论它连接到哪个服务器。</li>
  <li>可靠性：一旦更新成功，那么这种更新将是永久性的，直到下次更新。</li>
  <li>时效性：在client看来，一个更新操作后，zookeeper将在一个固定的时间内，更新所有的zookeeper server。</li>
</ul>

<h3 id="simple-api">Simple API</h3>

<p>ZooKeeper提供了非常简单的编程接口，它仅仅支持以下操作:</p>

<ul>
  <li>create 创建一个znode节点</li>
  <li>delete 删除一个znode节点</li>
  <li>exists 测试一个znode节点是否存在</li>
  <li>get data 读取一个znode节点的数据</li>
  <li>set data 写一个znode节点的数据</li>
  <li>get children 写一个znode节点的children列表</li>
  <li>sync 等待znode节点的数据，在zookeeper server中同步</li>
</ul>

<h3 id="implementations">Implementations</h3>

<p>下图展示了ZK的模块图，这个模块图是非常顶层和概要的。除了request processor不相同以外，其余的所有的ZK service中的server都有每个模块的一模一样的副本。</p>

<p><img class="center" src="/images/blogimages/2013/zk-overview/zkcomponents.jpg"></p>

<p>replicated database 存放了所有的数据，并且存放在内存中。所有的更新就会以日志的形式记录到磁盘中，以便可以用于灾后重建，所有的写操作，都先序列化到磁盘中，然后再写到内存中的database中。</p>

<p>每个zk server为zk clients服务，zk客户端连接到一台zk服务器上，而且只能连接到一台，并向服务器发送请求。所有的读请求，都有zk server从本地的replica database中直接获取数据。所有写请求，或是改变服务状态的请求，zk会基于一个agreement protocol进行处理。</p>

<p>agreement protocol的一部分，就是所有的来自客户端的写请求，就讲被转发到一个特定的zk server上（这个zk server被称为leader，其余的zk server称为followers）这时，所有的followers就会接收到来自leader的一个“提议消息”，并且同意这个消息。</p>

<p>替换leader或同步followers的工作是有messaging layer完成的。</p>

<h3 id="performance">Performance</h3>

<p>ZooKeeper的一个目标就是高性能。由雅虎研究院开发zookeeper的小组所做的测试实验证明了zk的高性能。下图是他们的实验结果：
ZooKeeper Throughput as the Read-Write Ratio Varies
<img class="center" src="/images/blogimages/2013/zk-overview/zkperfRW-3.2.jpg"></p>

<p>当读请求远远高于写请求时zk的性能会更好。因为写请求需要同步所有的zk server。通常情况下当读写比例为10：1时，性能就可以达到一个比较好的效果了。</p>

<h3 id="reliability">Reliability</h3>

<p>在zookeeper的介绍页面，还有关于failure的一个实验。实验表明zk在存在failure的情况下，依然可以保证比较高的吞吐能力。但更重要的是，leader选举算法可以保证系统能够很快从错误中恢复正常。在实验中观察，选举出新的leader的耗时少于200毫秒。当follower恢复正常后，zk的吞吐能力马上就上去了。</p>

<h3 id="section-2">连接库</h3>

<p>zookeeper可以通过多种方式连接，正式发布包里面包含了java和C种方式进行连接（就是客户端），C连接方式，有个库，单线程的zookeeper_st和多线程的zookeeper_mt。
zookeeper_st放弃了事件循环，可在事件驱动的应用程序中使用。而zookeeper_mt更加易用，与Java API类似，创建一个网络IO线程和一个事件分发线程，用来维护连接和执行回调。
在具体使用上，zookeeper_st仅提供了异步API与回调，用以集成至应用程序的事件循环。它只是为了支持pthread库不可用或不稳定的平台而存在，例如FreeBSD 4.x。除此以外的其他情况，应使用提供同步与异步两种API的zookeeper_mt。[^1]</p>

<p>当然还有其它语言非正式发布的连接库：<a href="https://cwiki.apache.org/confluence/display/ZOOKEEPER/ZKClientBindings">ZKClientBindings</a>。</p>

<h3 id="zk">zk集群</h3>

<p>配置zookeeper集群其实也是比较简单地的。配置方法就是standalone mode的配置文件基础上添加几个配置项，下面是一个示例：</p>

<p><code>
tickTime=2000
dataDir=/var/lib/zookeeper
clientPort=2181
initLimit=5
syncLimit=2
server.1=zoo1:2888:3888
server.2=zoo2:2888:3888
server.3=zoo3:2888:3888
</code></p>

<p>单机版中包含了<code>tickTime</code>，<code>dataDir</code>，<code>clientPort</code>三个配置项。<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup></p>

<ul>
  <li>tickTime 是zk的时钟周期，单位是毫秒。Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime时间就会发送一个心跳。tickTime以毫秒为单位。</li>
  <li>dataDir 保存数据的目录，默认情况下，Zookeeper将写数据的日志文件也保存在这个目录里。</li>
  <li>clientPort 客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。</li>
</ul>

<p>在集群配置中多出来了，<code>initLimit</code>，<code>syncLimit</code>，<code>server.x</code>配置项。</p>

<ul>
  <li>initLimit 集群中的follower服务器(F)与leader服务器(L)之间初始连接时能容忍的最多心跳数（tickTime的数量）。</li>
  <li>syncLimit 集群中的follower服务器与leader服务器之间请求和应答之间能容忍的最多心跳数（tickTime的数量）。</li>
  <li>server.X  集群信息（服务器编号，服务器地址，Leader Followers通信端口，选举端口）     <br />
  这个配置项的书写格式比较特殊，规则如下：  <br />
      server.N=YYY:A:B   <br />
  其中N表示服务器编号，YYY表示服务器的IP地址，A为leader followers(LF)通信端口，表示该服务器与集群中的leader交换的信息的端口。B为选举端口，表示选举新leader时服务器间相互通信的端口（当leader挂掉时，其余服务器会相互通信，选择出新的leader），连接方式也是tcp。一般来说，集群中每个服务器的A端口都是一样，每个服务器的B端口也是一样。但是当所采用的为伪集群时（所有的zk server在一台服务器上），IP地址都一样，只能时A端口和B端口不一样。     <br />
  当一台zk服务器启动时，它通过查看myid文件，可以知道自己是这些配置中的哪一台服务器。myid文件包含了服务器的数字编号。</li>
</ul>

<h2 id="section-3">试用</h2>

<p>先装一个zookeeper Standalone来试试。安装和配置还是十分简单的，参考<a href="http://zookeeper.apache.org/doc/r3.4.5/zookeeperStarted.html">ZooKeeper Getting Started Guide</a>上面讲到地，进行就可以了。配置完后，就可以启动zookeeper了，启动命令可以参考前面的Guide。</p>

<p>zooker启动后可以使用客户端连接zookeeper service了，有两种客户端使用，一是java版，另外一个是c版的。可以先使用java版的练习一下。</p>

<p>实际上启动了java的client后，看到的是一个类是shell的交互式界面了，通过这个shell可以做很多事情，通过命令<code>help</code>来查看。</p>

<pre><code>[zkshell: 0] help
    ZooKeeper host:port cmd args
    get path [watch]
    ls path [watch]
    set path data [version]
    delquota [-n|-b] path
    quit
    printwatches on|off
    createpath data acl
    stat path [watch]
    listquota path
    history
    setAcl path acl
    getAcl path
    sync path
    redo cmdno
    addauth scheme auth
    delete path [version]
    setquota -n|-b val path
</code></pre>

<p><a href="http://zookeeper.apache.org/doc/r3.4.5/zookeeperStarted.html">ZooKeeper Getting Started Guide</a>还举一个通过zkshell进行znode的创建、查看、更新、删除等操作。</p>

<h2 id="section-4">总结</h2>

<p>上面简单介绍了zookeeper，包括zookeeper的一些概念和框架等，绝大部分是直接翻译了<a href="http://zookeeper.apache.org/doc/trunk/zookeeperOver.html">zookeeper Overview</a>。下一篇文章就讲讲<a href="http://zookeeper.apache.org/doc/r3.4.5/zookeeperProgrammers.html">ZooKeeper Programmer’s Guide</a>，当然重点是C binding。</p>

<p>在网上查找zookeeper的资料时，找到了几篇不错的文章<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup><sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup><sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup><sup id="fnref:6"><a href="#fn:6" rel="footnote">6</a></sup>，大家可以一读。另外还找到一篇介绍google的chubby的不错的blog——<a href="http://blog.csdn.net/historyasamirror/article/details/3870168">Google利器之Chubby</a>，这个blog还写了关于google的分布式重用的5篇论文的文章，第一篇是<a href="http://blog.csdn.net/historyasamirror/article/details/3861144">Google利器之Google Cluster</a>，如果大家有兴趣可以顺着读下去看一看。</p>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p><a href="http://baike.baidu.com/view/3061646.htm">http://baike.baidu.com/view/3061646.htm</a><a href="#fnref:1" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p><a href="http://blog.csdn.net/poechant/article/details/6650249">http://blog.csdn.net/poechant/article/details/6650249</a><a href="#fnref:2" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:3">
      <p><a href="http://www.cnblogs.com/caosiyang/archive/2012/11/09/2763190.html">ZooKeeper编程笔记</a><a href="#fnref:3" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:4">
      <p><a href="http://www.oschina.net/p/zookeeper">http://www.oschina.net/p/zookeeper</a><a href="#fnref:4" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:5">
      <p><a href="http://bbs.zoomla.cn/archiver/showtopic-15086.aspx">http://bbs.zoomla.cn/archiver/showtopic-15086.aspx</a><a href="#fnref:5" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:6">
      <p><a href="http://liyanblog.cn/articles/2012/09/28/1348814456421.html">http://liyanblog.cn/articles/2012/09/28/1348814456421.html</a><a href="#fnref:6" rel="reference">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[elasticsearch之基本操作]]></title>
    <link href="http://liuhongjiang.github.com/tech/blog/2013/01/11/es/"/>
    <updated>2013-01-11T17:08:00+08:00</updated>
    <id>http://liuhongjiang.github.com/tech/blog/2013/01/11/es</id>
    <content type="html"><![CDATA[<p><a href="http://www.elasticsearch.org">elasticsearch</a>是一个是开源的（Apache2协议），分布式的，<a href="http://zh.wikipedia.org/zh-cn/REST">RESTful</a>的，构建在<a href="http://lucene.apache.org/">Apache Lucene</a>之上的的搜索引擎。 </p>

<p>它有很多特点例如Schema Free，Document Oriented。它是#nosql的，基于JSON，同时支持多种API，包括HTTP, thrift, memcached。支持HTTP,是比较爽的一点，因为基本上所有的应用都可以用ES了，页面上的js脚本都可以去查询。</p>

<h2 id="section">安装</h2>

<p>启动和安装特别简单，在<a href="http://www.elasticsearch.org/download/">ES下载页面</a>下载zip或者tar包后，解压，然后到elasticsearch的目录下，运行下面的命令就可以了。</p>

<p><pre class='sh-commands'><code>bin/elasticsearch -f</code></pre></p>

<p>搭建集群也非常简单，在同网段的机器上，启动es后，它们会自动组建成一个集群，并完成数据的分布式存储，查询时也会按照分布式的方式去查找。</p>

<p>好了恭喜你，现在你已经可以搭建ES单机版和ES集群了，一切都这么简单。</p>

<!-- more -->

<p>下面我们就来看一下ES的HTTP的API的插入、删除、更新、查找、搜索的功能吧，（ES安装在ubuntu server 64位 12.04LTS）。</p>

<h2 id="section-1">插入</h2>

<p>先来一个简单的官方例子，插入的参数为<code>-XPUT</code>，插入一条记录。</p>

<pre class="sh-bash"><code>$ curl -XPUT 'http://localhost:9200/twitter/tweet/1' -d '{
    "user" : "kimchy",
    "post_date" : "2009-11-15T14:12:12",
    "message" : "trying out Elastic Search"
}'
</code></pre>

<p>执行结果如下图所示，绿色框内的内容是ES返回的执行结果：</p>

<p><pre class='sh-bash'><code>andrew@ubuntu:~$ curl -XPUT ‘http://localhost:9200/twitter/tweet/1’ -d ‘{
</code><code>&amp;gt;     “user” : “kimchy”,
</code><code>&amp;gt;     “post_date” : “2009-11-15T14:12:12”,
</code><code>&amp;gt;     “message” : “trying out Elastic Search”
</code><code>&amp;gt; }’
</code><code>{“ok”:true,”_index”:”twitter”,”_type”:”tweet”,”_id”:”1”,”_version”:6}andrew@ubuntu:~$</code></pre></p>

<p>从上面的这个例子中，可以看出ES的http的服务的默认端口9200，后面的<code>/twitter/tweet/1</code>是这条记录的索引部分。</p>

<p>这也就体现了它的RESTful风格，所有的记录都是通过URI确定。这三级目录分布对应了<code>_index</code>，<code>_type</code>, <code>_id</code>（绿框内可以看出来）。实际上ES上存放的所有的记录都只能通过三级目录的方式找到，不能多也不能少。</p>

<p><code>_id</code>字段可以是数字也可以是字符串。在执行上面的命令时ES会自动创建这些索引。<code>-d</code>后面跟上了要插入的json格式的记录。</p>

<p><code>-XPUT</code>表明这是插入一条数据，ES中叫创建一个索引。ES返回的结果中，一个<code>_version</code>字段，表明了当前记录的版本号，当你想这个索引重新put一条记录时，版本号会自动加一。</p>

<h2 id="section-2">删除</h2>

<p>删除的http请求参数为<code>-XDELETE</code>，通过下面的命令可以删除这条记录：</p>

<pre class="sh-commands"><code>curl -XDELETE 'http://localhost:9200/twitter/tweet/1'
</code></pre>

<p>删除这条记录的时候，<code>_verison</code>也会自动加一的。</p>

<h2 id="section-3">查询</h2>

<p>创建了一个索引后，可以通过下面的方式查询（参数<code>-XGET</code>）出来:</p>

<pre class="sh-commands"><code>curl -XGET 'http://localhost:9200/twitter/tweet/1'
</code></pre>

<p>执行上面的查询命令，可以等到下面的结果：</p>

<pre class="sh-bash"><code>andrew@ubuntu:~$ curl -XGET 'http://localhost:9200/twitter/tweet/1'
{"_index":"twitter","_type":"tweet","_id":"1","_version":5,"exists":true, "_source" : {
    "user" : "kimchy",
    "post_date" : "2009-11-15T14:12:12",
    "message" : "trying out Elastic Search"
}}andrew@ubuntu:~$ 
</code></pre>

<p><code>exists</code>表示是否有查询结果，<code>_source</code>字段是查询到的记录。</p>

<p>查询的时候，可以将<code>_type</code>设置成为<code>_all</code>，ES就会返回在<code>_index</code>下所有type中，第一个匹配<code>_id</code>的记录。</p>

<p>还可以通过参数对返回结果继续控制，例如：用fields选取返回的字段，用pretty控制返回的json格式是否更阅读友好。<code>format=yaml</code>可以设置输入格式为YAML。
下面是两个例子</p>

<p><pre class='sh-commands'><code>curl -XGET ‘http://localhost:9200/twitter/tweet/1?fields=message,user&amp;amp;pretty=true’
</code><code>curl -XGET ‘http://localhost:9200/twitter/tweet/1?fields=message,user&amp;amp;format=yaml’</code></pre></p>

<p>当然ES还支持一次查询多组记录，即multi get，在URI中是使用关键字<code>_mget</code>，具体可以参考ES的文档<a href="http://www.elasticsearch.org/guide/reference/api/multi-get.html">multi get</a>。</p>

<h2 id="section-4">更新</h2>

<p>ES同样支持更新，但是更新的方式是通过一个提供的脚本进行的。ES的做法是，通过index找到相应的存放记录的节点，然后执行脚本，执行完之后，返回新的索引。实际上执行的是一个get和reindex的过程，在这个过程中，通过versioning来控制没有其它的更新操作（这个功能是0.19后可用的）。具体实现的原理应该和<a href="http://www.elasticsearch.org/blog/2011/02/08/versioning.html">elasticsearch Versioning</a>相关。</p>

<p>get，reindex的含义是，ES先取出这条记录，然后根据新数据生成新记录，然后在把新记录放回到ES中（并不会覆盖老的记录）。</p>

<p>首先创建一条记录</p>

<pre class="sh-bash"><code>$ curl -XPUT localhost:9200/test/type1/1 -d '{
    "counter" : 1,
    "tags" : ["red"]
}'
</code></pre>

<p>将counter的值加4</p>

<pre class="sh-bash"><code>$ curl -XPOST 'localhost:9200/test/type1/1/_update' -d '{
    "script" : "ctx._source.counter += count",
    "params" : {
        "count" : 4
    }
}'
</code></pre>

<p>也可以添加一个tag的值</p>

<pre class="sh-bash"><code>$ curl -XPOST 'localhost:9200/test/type1/1/_update' -d '{
    "script" : "ctx._source.tags += tag",
    "params" : {
        "tag" : "blue"
    }
}'
</code></pre>

<p>现在还支持upsert功能，即在更新的时候，如果记录没有这个key，则插入这个key，下面是一个例子，如果没有<code>counter</code>字段，则插入该字段：</p>

<pre class="sh-bash"><code>$ curl -XPOST 'localhost:9200/test/type1/1/_update' -d '{
    "script" : "ctx._source.counter += count",
    "params" : {
        "count" : 4
    },
    "upsert" : {
        "counter" : 1
    }
}'
</code></pre>

<p>关于update还有其它很多功能，可以参考<a href="http://www.elasticsearch.org/guide/reference/api/update.html">ES的API update</a></p>

<h2 id="section-5">搜索</h2>

<p>elasticsearch的名字里面有一个search，那么主要功能也是search了。</p>

<p>es的search有两种形式，一是通过URI，二是通过Requst Body。通过URI查询，即将查询的语句放入到请求的url中，例如：</p>

<pre class="sh-commands"><code>curl -XGET 'http://localhost:9200/twitter/tweet/_search?q=user:kimchy'
</code></pre>

<p>第二种方式，即在查询的请求中加入一个doc</p>

<pre class="sh-bash"><code>$ curl -XGET 'http://localhost:9200/twitter/tweet/_search' -d '{
    "query" : {
        "term" : { "user" : "kimchy" }
    }
}'
</code></pre>

<p>query body的定义可以查看<a href="http://www.elasticsearch.org/guide/reference/query-dsl/">query DSL</a>
另外两种查询方式都可以带参数，参数的含义参考<a href="http://www.elasticsearch.org/guide/reference/api/search/uri-request.html">URI Request</a>和<a href="http://www.elasticsearch.org/guide/reference/api/search/request-body.html">Request Body</a>。</p>

<p>ES的搜索功能是可以跨index和type的，例如下面这几条命令</p>

<p><pre class='sh-commands'><code>curl -XGET ‘http://localhost:9200/twitter/_search?q=user:kimchy’
</code><code>curl -XGET ‘http://localhost:9200/twitter/tweet,user/_search?q=user:kimchy’
</code><code>curl -XGET ‘http://localhost:9200/kimchy,elasticsearch/tweet/_search?q=tag:wow’
</code><code>curl -XGET ‘http://localhost:9200/_all/tweet/_search?q=tag:wow’
</code><code>curl -XGET ‘http://localhost:9200/_search?q=tag:wow’</code></pre></p>

<p>第一条是在所有的<code>twitter</code>这个index下的所有type中查找，第二条是在<code>tweet,user</code>这两个type中查找，第三条是在<code>kimchy,elasticsearch</code>这两个index的<code>tweet</code>这个type中查找，第四条使用了<code>_all</code>关键字，是在所有的index的<code>tweet</code>的type中查找，第五条更暴力，在所有的index和type中查找。</p>

<p>查找还有其它的很多选项，<a href="http://www.elasticsearch.org/guide/reference/api/search/sort.html">sort</a>，<a href="http://www.elasticsearch.org/guide/reference/api/search/highlighting.html">高亮</a>，选取返回记录的域<a href="http://www.elasticsearch.org/guide/reference/api/search/fields.html">Fields</a>，还可以对返回的域使用一个脚本进行计算<a href="http://www.elasticsearch.org/guide/reference/api/search/script-fields.html">script Fields</a>，或者对返回结果继续统计<a href="http://www.elasticsearch.org/guide/reference/api/search/facets/">Facets</a>，Facets的内容比较多，它支持关键词统计，范围内统计，直方图式统计，日期的直方图式统计，过滤，查询，还有记录地理位置距离的统计<a href="http://www.elasticsearch.org/guide/reference/api/search/facets/geo-distance-facet.html">geo distance</a>。
支持名字过滤<a href="http://www.elasticsearch.org/guide/reference/api/search/named-filters.html">Named Filters</a>。
定义搜索类型<a href="http://www.elasticsearch.org/guide/reference/api/search/search-type.html">Search Type </a>。例如什么Query And Fetch，Query Then Fetch。
索引加速的功能<a href="http://www.elasticsearch.org/guide/reference/api/search/index-boost.html">Index Boost</a>，可以让某一个索引的权重大于另外一个。
保持上次检索的环境了结果<a href="http://www.elasticsearch.org/guide/reference/api/search/scroll.html">Scroll</a>。保留每一个命中的score值<a href="http://www.elasticsearch.org/guide/reference/api/search/explain.html">Explain</a>。
设置命中的<a href="http://www.elasticsearch.org/guide/reference/api/search/min-score.html">min_score</a>。保留版本号<a href="http://www.elasticsearch.org/guide/reference/api/search/version.html">Version</a>。</p>

<p>Search的参数很多，我也没有一一看，不过果然是名字里面有个search，对检索的各种场景都有支持。</p>

<p>当然还支持多个查询multi search，例如下面这个例子</p>

<pre class="sh-bash"><code>$ cat requests
{"index" : "test"}
{"query" : {"match_all" : {}}, "from" : 0, "size" : 10}
{"index" : "test", "search_type" : "count"}
{"query" : {"match_all" : {}}}
{}
{"query" : {"match_all" : {}}}

$ curl -XGET localhost:9200/_msearch --data-binary @requests; echo
</code></pre>

<h2 id="section-6">小结</h2>

<p>以上就是elasticsearch的基本的几个功能了。当然它还有其它的很多功能，大家可以上<a href="http://www.elasticsearch.org">http://www.elasticsearch.org</a>去查看。</p>

<p>ES是基于Lucene的，有很多概念是直接来自于它，所有要想深入学习ES，还得有点Lucene的基础。</p>

<p>总的，感觉elasticsearch是一个比较强大的工具，而且对社交网络的支持比较好，而且使用方便，配置简单，就不知道稳定性如何了。</p>

<p>下面是两篇不错的文章，大家也可以借鉴一下：</p>

<ul>
  <li><a href="http://blog.csdn.net/laigood12345/article/details/7421173">http://blog.csdn.net/laigood12345/article/details/7421173</a></li>
  <li><a href="http://www.qwolf.com/?p=1387">http://www.qwolf.com/?p=1387</a></li>
</ul>

<p>还有elasticsearch的中文站点<a href="http://www.elasticsearch.cn/">http://www.elasticsearch.cn/</a>，不过这个网站还在构建中，翻译工作也才刚刚开始，大家就期盼早点完成。</p>
]]></content>
  </entry>
  
</feed>
